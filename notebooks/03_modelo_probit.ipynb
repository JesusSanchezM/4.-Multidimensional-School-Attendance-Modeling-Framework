{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59eabded",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlite3\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msm\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformula\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. CARGA DE DATOS\n",
    "# -------------------------------------------------------------------------\n",
    "DB_PATH = Path(\"../data/processed/enigh_unificada.db\")\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df = pd.read_sql(\"SELECT * FROM tabla_analitica_final\", conn)\n",
    "conn.close()\n",
    "\n",
    "# 2. LIMPIEZA Y PREPARACIÓN DE VARIABLES (Tu sección 'gen')\n",
    "# -------------------------------------------------------------------------\n",
    "# Binarias\n",
    "df['asis_esc_bin'] = (df['asis_esc'] == 1).astype(int)\n",
    "df['hombre'] = (df['sexo'] == 1).astype(int)\n",
    "df['discapacidad'] = df['presenta_alguna_discapacidad'].fillna(0).astype(int) # Asumimos 0 si es nulo\n",
    "df['indigena'] = (df['etnia'] == 1).astype(int)\n",
    "df['urbano'] = (df['ambito'] == 'Urbano').astype(int)\n",
    "df['internet'] = df['tiene_internet'].astype(int)\n",
    "\n",
    "# Numéricas\n",
    "df['ingreso_pc_miles'] = df['ingreso_total_hogar_per_capita_sin_jovenes'] / 1000\n",
    "# Logaritmo (sumamos 0.01 para evitar log(0))\n",
    "df['ln_ingreso'] = np.log(df['ingreso_pc_miles'] + 0.01) \n",
    "\n",
    "df['horas_no_estudio'] = df['total_minutos'] / 60\n",
    "df['tot_integ_num'] = df['tot_integ'] # Ya viene numérico desde SQL\n",
    "\n",
    "# Escolaridad Jefe (Recodificación 0-4)\n",
    "# En SQL ya lo hicimos como 'escolaridad_num' pero era del individuo. \n",
    "# Necesitamos la del padre (edu_padre) o madre (edu_madre) o jefe (educa_jefe).\n",
    "# En tu código Stata usas 'escolaridad_final' derivada de 'escolaridad_101'.\n",
    "# En la tabla final tenemos 'edu_padre' y 'edu_madre'.\n",
    "# Usaremos el máximo de los padres como proxy del capital cultural\n",
    "df['escolaridad_padres'] = df[['edu_padre', 'edu_madre']].max(axis=1).fillna(0)\n",
    "\n",
    "# Regiones a Dummies (Categorical)\n",
    "# Statsmodels maneja automáticamente categorías si definimos la columna\n",
    "df['region'] = df['region'].astype('category')\n",
    "\n",
    "# 3. FILTRADO DE MUESTRA (Tu lógica de Percentiles)\n",
    "# -------------------------------------------------------------------------\n",
    "def get_sample_mask(data, year, min_age, max_age):\n",
    "    # Filtramos por año y edad primero\n",
    "    subset = data[(data['anio'] == year) & (data['edad'] >= min_age) & (data['edad'] <= max_age)]\n",
    "    \n",
    "    # Calculamos percentiles en ese subgrupo\n",
    "    p1_ing = subset['ingreso_total_hogar_per_capita_sin_jovenes'].quantile(0.01)\n",
    "    p99_ing = subset['ingreso_total_hogar_per_capita_sin_jovenes'].quantile(0.99)\n",
    "    \n",
    "    p1_hrs = subset['total_minutos'].quantile(0.01)\n",
    "    p99_hrs = subset['total_minutos'].quantile(0.99)\n",
    "    \n",
    "    # Creamos la máscara booleana global\n",
    "    mask = (\n",
    "        (data['anio'] == year) &\n",
    "        (data['edad'] >= min_age) & \n",
    "        (data['edad'] <= max_age) &\n",
    "        (data['ingreso_total_hogar_per_capita_sin_jovenes'] > p1_ing) &\n",
    "        (data['ingreso_total_hogar_per_capita_sin_jovenes'] < p99_ing) &\n",
    "        (data['total_minutos'] > p1_hrs) &\n",
    "        (data['total_minutos'] < p99_hrs) &\n",
    "        # Filtro de Hijos/Nietos (Parentesco 3xx)\n",
    "        (data['parentesco'].isin([301, 302, 303, 304]))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "# Definimos las muestras\n",
    "mask_m1 = get_sample_mask(df, 2018, 15, 17) # Media Superior 2018\n",
    "mask_m2 = get_sample_mask(df, 2018, 18, 24) # Superior 2018\n",
    "mask_m3 = get_sample_mask(df, 2024, 15, 17) # Media Superior 2024\n",
    "mask_m4 = get_sample_mask(df, 2024, 18, 24) # Superior 2024\n",
    "\n",
    "print(f\"Muestras definidas:\\nM1: {mask_m1.sum()}\\nM2: {mask_m2.sum()}\\nM3: {mask_m3.sum()}\\nM4: {mask_m4.sum()}\")\n",
    "\n",
    "# 4. DEFINICIÓN DEL MODELO PROBIT\n",
    "# -------------------------------------------------------------------------\n",
    "# Fórmula estilo R/Stata\n",
    "formula_base = \"\"\"\n",
    "asis_esc_bin ~ discapacidad + horas_no_estudio + ln_ingreso + \n",
    "               C(escolaridad_padres) + internet + hombre + edad + \n",
    "               indigena + urbano + tot_integ_num + \n",
    "               C(region) + razon_alumnos_escuelas\n",
    "\"\"\"\n",
    "\n",
    "# Agregamos las variables específicas por nivel educativo\n",
    "formula_ms = formula_base + \" + ratio_ems_ent + pct_prepa_o_mas\"\n",
    "formula_sup = formula_base + \" + ratio_superior_ent + pct_lic_o_mas\"\n",
    "\n",
    "def run_probit(data, mask, formula, model_name):\n",
    "    print(f\"\\n--- Estimando {model_name} ---\")\n",
    "    \n",
    "    # Subconjunto de datos\n",
    "    df_model = data[mask].copy()\n",
    "    \n",
    "    # Eliminar NAs en las variables del modelo\n",
    "    # Statsmodels falla si hay NAs\n",
    "    df_model = df_model.dropna(subset=[\n",
    "        'asis_esc_bin', 'discapacidad', 'horas_no_estudio', 'ln_ingreso',\n",
    "        'escolaridad_padres', 'internet', 'hombre', 'edad', 'indigena',\n",
    "        'urbano', 'tot_integ_num', 'region', 'razon_alumnos_escuelas',\n",
    "        'factor', 'upm'\n",
    "    ])\n",
    "    \n",
    "    # Modelo GLM con familia Binomial y enlace Probit (Equivalente a probit)\n",
    "    # Usamos freq_weights para el factor de expansión\n",
    "    model = smf.glm(\n",
    "        formula=formula, \n",
    "        data=df_model, \n",
    "        family=sm.families.Binomial(link=sm.families.links.probit()),\n",
    "        freq_weights=df_model['factor']\n",
    "    )\n",
    "    \n",
    "    # Ajuste con errores robustos agrupados (Cluster por UPM)\n",
    "    # Esto simula el svy: vce(linearized)\n",
    "    result = model.fit(cov_type='cluster', cov_kwds={'groups': df_model['upm']})\n",
    "    \n",
    "    print(result.summary())\n",
    "    \n",
    "    # Efectos Marginales (dydx)\n",
    "    print(f\"Calculando Efectos Marginales para {model_name}...\")\n",
    "    margeff = result.get_margeff(at='overall')\n",
    "    print(margeff.summary())\n",
    "    \n",
    "    return result, margeff\n",
    "\n",
    "# 5. EJECUCIÓN DE MODELOS\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# --- 2018 ---\n",
    "res_m1, me_m1 = run_probit(df, mask_m1, formula_ms, \"M1: Media Sup 2018\")\n",
    "res_m2, me_m2 = run_probit(df, mask_m2, formula_sup, \"M2: Superior 2018\")\n",
    "\n",
    "# --- 2024 ---\n",
    "res_m3, me_m3 = run_probit(df, mask_m3, formula_ms, \"M3: Media Sup 2024\")\n",
    "res_m4, me_m4 = run_probit(df, mask_m4, formula_sup, \"M4: Superior 2024\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
